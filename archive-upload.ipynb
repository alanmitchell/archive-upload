{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of Archive-Upload Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "import bz2\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Design\n",
    "\n",
    "* When a finished file is found, compressed, and archived, immediately try\n",
    "  to upload.  If the upload fails, add the file to the \"database\" of files\n",
    "  that need to be uploaded.  That database of pending uploads should hold\n",
    "  the local file path and the destination S3 bucket.  It could just be a list\n",
    "  of two-tuples that is pickled to disk in the ~/.archive-upload directory.\n",
    "* For the newly finished file, may just want to append it to the \"upload pending\"\n",
    "  list, and then after that start trying to work through the list, uploading\n",
    "  the oldest file first.\n",
    "* The AWS sync command may not be the best because if someone cleans out the S3\n",
    "  bucket, the script will try to re-upload all of the local files in the archive\n",
    "  directory.  The approach aboves solves that problem by only uploading a file once\n",
    "  to S3.  It also has the advantage of only requiring Python boto3 methods (not\n",
    "  needing a AWS command line utility)\n",
    "* Archiving and Uploading application log files may be tricky.  Rotating file handler will\n",
    "  keep producing files of the same names: archive-upload.log, archive-upload.log.1, etc.  One idea\n",
    "  might be to take the last X lines of error file at the end of the day and copy\n",
    "  those lines into a day-specific log file: 2019-07-23_archive-upload.log.  Then this utility\n",
    "  could archive and upload those files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting archive-upload-example.config\n"
     ]
    }
   ],
   "source": [
    "%%writefile archive-upload-example.config\n",
    "directories:\n",
    "  - directory: /home/tabb99/arch-test/abc\n",
    "    file-patterns: \n",
    "      - pattern: \"*.csv\"\n",
    "        finished-secs: 2600\n",
    "      - pattern: \"*.log\"\n",
    "        finished-secs: 3000\n",
    "    bucket: orca.acep.org/abc\n",
    "    archive-dir: /home/tabb99/arch-test/archive/abc\n",
    "    delete-after: 365          # days\n",
    "  - directory: /home/tabb99/arch-test/xyz\n",
    "    file-patterns:\n",
    "      - pattern: \"*.txt\"\n",
    "        finished-secs: 500\n",
    "    bucket: orca.acep.org/xyz\n",
    "    archive-dir: /home/tabb99/arch-test/archive/xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'directories': [{'archive-dir': '/home/tabb99/arch-test/archive/abc',\n",
      "                  'bucket': 'orca.acep.org/abc',\n",
      "                  'delete-after': 365,\n",
      "                  'directory': '/home/tabb99/arch-test/abc',\n",
      "                  'file-patterns': [{'finished-secs': 2600, 'pattern': '*.csv'},\n",
      "                                    {'finished-secs': 3000,\n",
      "                                     'pattern': '*.log'}]},\n",
      "                 {'archive-dir': '/home/tabb99/arch-test/archive/xyz',\n",
      "                  'bucket': 'orca.acep.org/xyz',\n",
      "                  'directory': '/home/tabb99/arch-test/xyz',\n",
      "                  'file-patterns': [{'finished-secs': 500,\n",
      "                                     'pattern': '*.txt'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# Read in the configuration file that controls execution of the script.\n",
    "cfg_fn = 'archive-upload-example.config'\n",
    "config = yaml.safe_load(open(cfg_fn, 'r'))\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Files to Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/tabb99/arch-test\n",
    "touch abc/hello01.csv\n",
    "touch abc/hello02.csv\n",
    "touch abc/another01.log\n",
    "touch abc/another02.log\n",
    "touch abc/junk\n",
    "touch xyz/another01.txt\n",
    "touch xyz/another02.txt\n",
    "touch xyz/junk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Application working directory if it does not exist.\n",
    "p_app = Path('~').expanduser() / '.archive-upload'\n",
    "p_app.mkdir(exist_ok=True)\n",
    "p_up_pending = p_app / 'upload_pending.pkl'\n",
    "\n",
    "# Read a list of pending uploads, if file is present, otherwise,\n",
    "# set to empty list.\n",
    "if p_up_pending.exists():\n",
    "    with p_up_pending.open('rb') as fin:\n",
    "        upload_pending = pickle.load(fin)\n",
    "else:\n",
    "    upload_pending = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete /home/tabb99/arch-test/abc/hello01.csv, 3548 secs old\n",
      "complete /home/tabb99/arch-test/abc/hello02.csv, 3548 secs old\n",
      "complete /home/tabb99/arch-test/abc/another01.log, 3548 secs old\n",
      "complete /home/tabb99/arch-test/abc/another02.log, 3548 secs old\n",
      "complete /home/tabb99/arch-test/xyz/another01.txt, 3548 secs old\n",
      "complete /home/tabb99/arch-test/xyz/another02.txt, 3548 secs old\n"
     ]
    }
   ],
   "source": [
    "# Loop through the list of directories, looking for completed files.\n",
    "for dr in config['directories']:\n",
    "    # Path to directory holding data files\n",
    "    p_dr = Path(dr['directory'])\n",
    "    \n",
    "    # Path to directory where finished, compressed files will be archived\n",
    "    p_archive = Path(dr['archive-dir'])\n",
    "    \n",
    "    # make the archive directory if it does not exists\n",
    "    p_archive.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Loop through file patterns\n",
    "    for pat in dr['file-patterns']:\n",
    "        for p_f in p_dr.glob(pat['pattern']):\n",
    "            # p_f is a Path to a file matching the pattern.\n",
    "            # test to see if it is a completed file\n",
    "            file_age = time.time() - p_f.stat().st_mtime\n",
    "            if file_age > pat['finished-secs']:\n",
    "                print(f'complete {p_f}, {file_age:.0f} secs old')\n",
    "                p_arch_fn = p_archive / (p_f.name + '.bz2')\n",
    "                with bz2.open(p_arch_fn, \"wb\") as fout:\n",
    "                  fout.write(p_f.read_bytes())\n",
    "\n",
    "            \n",
    "    # Check for files to delete in the archive directory\n",
    "    # but only delete if the file is not in the upload pending list.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the upload pending list\n",
    "with p_up_pending.open('wb') as fout:\n",
    "    pickle.dump(upload_pending, fout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
